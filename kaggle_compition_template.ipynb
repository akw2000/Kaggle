{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# kaggle compition template"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-17T10:12:14.881794Z",
     "iopub.status.busy": "2023-02-17T10:12:14.881323Z",
     "iopub.status.idle": "2023-02-17T10:12:16.484739Z",
     "shell.execute_reply": "2023-02-17T10:12:16.483400Z",
     "shell.execute_reply.started": "2023-02-17T10:12:14.881701Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "from termcolor import colored\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, plot_confusion_matrix\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV as gscv\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, ExtraTreesClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from scipy.stats import expon, uniform\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\")\n",
    "\n",
    "# compitition name\n",
    "compitionName = \"\"\n",
    "# Path of the file to read\n",
    "path = f'../input/{compitionName}/train.csv'\n",
    "\n",
    "train  = pd.read_csv(path)\n",
    "test = pd.read_csv(path)\n",
    "\n",
    "def get_mae(max_leaf_nodes, train_X, val_X, train_y, val_y):\n",
    "    model = DecisionTreeRegressor(max_leaf_nodes=max_leaf_nodes, random_state=0)\n",
    "    model.fit(train_X, train_y)\n",
    "    preds_val = model.predict(val_X)\n",
    "    mae = mean_absolute_error(val_y, preds_val)\n",
    "    return(mae)\n",
    "\n",
    "print(\"\\nSetup complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Basic info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view cols\n",
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Data\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Data\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Missing vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'The training data {train.shape}')\n",
    "print('MISSING VALUES IN TRAINING DATASET:')\n",
    "print(train.isna().sum()) \n",
    "print(sns.heatmap(train.isnull(),yticklabels=False,cbar=False,cmap='Blues'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'The test data {test.shape}')\n",
    "print('MISSING VALUES IN VALIDATION DATASET:')\n",
    "print(test.isna().sum())\n",
    "print(sns.heatmap(test.isnull(),yticklabels=False,cbar=False,cmap='Blues'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete rows with missing values\n",
    "train.dropna(axis=0, inplace=True)\n",
    "test.dropna(axis=0, inplace=True)\n",
    "# drop specific col\n",
    "train.drop(['sepal_width'], axis=1, inplace=True)\n",
    "test.drop(['sepal_width'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## delete rows containing missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "say something why delete?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test:(2735, 16), train:(1437, 15)\n"
     ]
    }
   ],
   "source": [
    "# try delete missing value\n",
    "df1.dropna(inplace=True,axis=0)\n",
    "df2.dropna(inplace=True,axis=0)\n",
    "print(f\"test:{df1.shape}, train:{df2.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check for duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"There are {x_train.duplicated().sum()} duplicate rows in training set\")\n",
    "print(f\"There are {x_test.duplicated().sum()} duplicate rows in training set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there are duplicates, assuming that they are not intentional, we will remove them to avoid bias in estimation of regression coefficients.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.drop_duplicates(inplace=True)\n",
    "x_test.drop_duplicates(inplace=True)\n",
    "print(f\"There are {x_train.duplicated().sum()} duplicate rows in training set\")\n",
    "print(f\"There are {x_test.duplicated().sum()} duplicate rows in training set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if same value is repeated for each column more than 99% of the data\n",
    "num_rows = len(dataset)\n",
    "\n",
    "for col in dataset.columns:\n",
    "    cnts = dataset[col].value_counts(dropna=False)\n",
    "    top_pct = (cnts/num_rows).iloc[0]\n",
    "    \n",
    "    if top_pct > 0.999:\n",
    "        print('{0}: {1:.2f}%'.format(col, top_pct*100))\n",
    "        print(cnts)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pair plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parit plot\n",
    "# View the relationships between variables; color code by species type\n",
    "di = {0.0: 'Setosa', 1.0: 'Versicolor', 2.0:'Virginica'} # dictionary\n",
    "\n",
    "plt.figure()\n",
    "sns.pairplot(dataset.replace({'species': di}), hue = \"species\", size=3, markers=[\"o\", \"s\", \"D\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#ploting the heatmap for correlation for original dataset\n",
    "ax = sns.heatmap(dataset.corr(), annot=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## MI(mutual information) scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions\n",
    "def make_mi_scores(X, y):\n",
    "    X = X.copy()\n",
    "    for colname in X.select_dtypes([\"object\", \"category\"]):\n",
    "        X[colname], _ = X[colname].factorize()\n",
    "    # All discrete features should now have integer dtypes\n",
    "    discrete_features = [pd.api.types.is_integer_dtype(t) for t in X.dtypes]\n",
    "    mi_scores = mutual_info_regression(X, y, discrete_features=discrete_features, random_state=0)\n",
    "    mi_scores = pd.Series(mi_scores, name=\"MI Scores\", index=X.columns)\n",
    "    mi_scores = mi_scores.sort_values(ascending=False)\n",
    "    return mi_scores\n",
    "\n",
    "\n",
    "def plot_mi_scores(scores):\n",
    "    scores = scores.sort_values(ascending=True)\n",
    "    width = np.arange(len(scores))\n",
    "    ticks = list(scores.index)\n",
    "    plt.barh(width, scores)\n",
    "    plt.yticks(width, ticks)\n",
    "X = train.copy()\n",
    "# target\n",
    "y = X.pop('SalePrice')\n",
    "mi_scores = make_mi_scores(X, y)  \n",
    "print(mi_scores.head(20))\n",
    "# print(mi_scores.tail(20))  # uncomment to see bottom 20\n",
    "\n",
    "plt.figure(dpi=100, figsize=(8, 5))\n",
    "plot_mi_scores(mi_scores.head(20))\n",
    "# plot_mi_scores(mi_scores.tail(20))  # uncomment to see bottom 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Skewness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the feature has 0.0 values, use np.log1p (log(1+x)) instead of np.log\n",
    "accidents[\"LogWindSpeed\"] = accidents.WindSpeed.apply(np.log1p)\n",
    "# Plot a comparison\n",
    "fig, axs = plt.subplots(1, 2, figsize=(8, 4))\n",
    "sns.kdeplot(accidents.WindSpeed, shade=True, ax=axs[0])\n",
    "sns.kdeplot(accidents.LogWindSpeed, shade=True, ax=axs[1]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create target object and call it y\n",
    "y = train.\n",
    "# Create X\n",
    "features = []\n",
    "X = train[features]\n",
    "X.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## One hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode BldgType. Use `prefix=\"Bldg\"` in `get_dummies`\n",
    "X_2 = pd.get_dummies(df.BldgType, prefix=\"Bldg\")\n",
    "# Multiply\n",
    "X_2 = X_2.mul(df.GrLivArea, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-17T10:12:14.881794Z",
     "iopub.status.busy": "2023-02-17T10:12:14.881323Z",
     "iopub.status.idle": "2023-02-17T10:12:16.484739Z",
     "shell.execute_reply": "2023-02-17T10:12:16.483400Z",
     "shell.execute_reply.started": "2023-02-17T10:12:14.881701Z"
    }
   },
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## target encoding\n",
    "Categorical features with a large number of categories are often good candidates\n",
    "\n",
    "almost any of the nominal features would be worth trying because of the prevalence of rare categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find unique cats\n",
    "df.select_dtypes([\"object\"]).nunique()\n",
    "# count for specific cat\n",
    "df[\"SaleType\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split\n",
    "# Encoding split\n",
    "X_encode = df.sample(frac=0.20, random_state=0)\n",
    "y_encode = X_encode.pop(\"SalePrice\")\n",
    "\n",
    "# Training split\n",
    "X_pretrain = df.drop(X_encode.index)\n",
    "y_train = X_pretrain.pop(\"SalePrice\")\n",
    "\n",
    "#encode\n",
    "from category_encoders import MEstimateEncoder\n",
    "\n",
    "# Create the encoder instance. Choose m to control noise.\n",
    "encoder = MEstimateEncoder(cols=[\"Zipcode\"], m=5.0)\n",
    "\n",
    "# Fit the encoder on the encoding split.\n",
    "encoder.fit(X_encode, y_encode)\n",
    "\n",
    "# Encode the Zipcode column to create the final training data\n",
    "X_train = encoder.transform(X_pretrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## k-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "# Create cluster feature\n",
    "kmeans = KMeans(n_clusters=6)\n",
    "\n",
    "# normalize\n",
    "# YOUR CODE HERE: Define a list of the features to be used for the clustering\n",
    "features = ['LotArea', 'TotalBsmtSF', 'FirstFlrSF', 'SecondFlrSF','GrLivArea']\n",
    "# Standardize\n",
    "X_scaled = X.loc[:, features]\n",
    "X_scaled = (X_scaled - X_scaled.mean(axis=0)) / X_scaled.std(axis=0)\n",
    "\n",
    "# fit\n",
    "X[\"Cluster\"] = kmeans.fit_predict(X)\n",
    "X[\"Cluster\"] = X[\"Cluster\"].astype(\"category\")\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 features\n",
    "sns.relplot(\n",
    "    x=\"Longitude\", y=\"Latitude\", hue=\"Cluster\", data=X, height=6,\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# standardize, cts, rm outliers\n",
    "if standardize:\n",
    "    X = (X - X.mean(axis=0)) / X.std(axis=0)\n",
    "# Create principal components\n",
    "pca = PCA()\n",
    "X_pca = pca.fit_transform(X)\n",
    "# Convert to dataframe\n",
    "component_names = [f\"PC{i+1}\" for i in range(X_pca.shape[1])]\n",
    "X_pca = pd.DataFrame(X_pca, columns=component_names)\n",
    "# Create loadings\n",
    "loadings = pd.DataFrame(\n",
    "    pca.components_.T,  # transpose the matrix of loadings\n",
    "    columns=component_names,  # so the columns are the principal components\n",
    "    index=X.columns,  # and the rows are the original features\n",
    ")\n",
    "\n",
    "X=X.join(X_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_dataset(X, y, model=XGBRegressor()):\n",
    "    # Label encoding for categoricals\n",
    "    for colname in X.select_dtypes([\"category\", \"object\"]):\n",
    "        X[colname], _ = X[colname].factorize()\n",
    "    # Metric for Housing competition is RMSLE (Root Mean Squared Log Error)\n",
    "    score = cross_val_score(\n",
    "        model, X, y, cv=5, scoring=\"neg_mean_squared_log_error\",\n",
    "    )\n",
    "    score = -1 * score.mean()\n",
    "    score = np.sqrt(score)\n",
    "    return score\n",
    "\n",
    "score = score_dataset(X, y)\n",
    "print(f\"Your score: {score:.5f} RMSLE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## split and train## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-17T10:12:14.881794Z",
     "iopub.status.busy": "2023-02-17T10:12:14.881323Z",
     "iopub.status.idle": "2023-02-17T10:12:16.484739Z",
     "shell.execute_reply": "2023-02-17T10:12:16.483400Z",
     "shell.execute_reply.started": "2023-02-17T10:12:14.881701Z"
    }
   },
   "outputs": [],
   "source": [
    "# Split into validation and training data\n",
    "train_X, val_X, train_y, val_y = train_test_split(X, y, \n",
    "                                                test_size= 0.2,\n",
    "                                                shuffle= True, #shuffle the data to avoid bias\n",
    "                                                random_state=1,\n",
    "                                                stratify=df['class'] #stratify the data to avoid bias)\n",
    "print(f'training set size: {X_train.shape[0]} samples \\ntest set size: {X_test.shape[0]} samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for max_leaf_nodes in [5, 50, 500, 5000]:\n",
    "    my_mae = get_mae(max_leaf_nodes, train_X, val_X, train_y, val_y)\n",
    "    print(\"Max leaf nodes: %d  \\t\\t Mean Absolute Error:  %d\" %(max_leaf_nodes, my_mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-17T10:12:14.881794Z",
     "iopub.status.busy": "2023-02-17T10:12:14.881323Z",
     "iopub.status.idle": "2023-02-17T10:12:16.484739Z",
     "shell.execute_reply": "2023-02-17T10:12:16.483400Z",
     "shell.execute_reply.started": "2023-02-17T10:12:14.881701Z"
    }
   },
   "outputs": [],
   "source": [
    "# Using best value for max_leaf_nodes\n",
    "model = DecisionTreeRegressor(max_leaf_nodes=100, random_state=1)\n",
    "model.fit(train_X, train_y)\n",
    "val_predictions = model.predict(val_X)\n",
    "val_mae = mean_absolute_error(val_predictions, val_y)\n",
    "print(\"Validation MAE for best value of max_leaf_nodes: {:,.0f}\".format(val_mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-17T10:13:50.465398Z",
     "iopub.status.busy": "2023-02-17T10:13:50.464923Z",
     "iopub.status.idle": "2023-02-17T10:13:51.004643Z",
     "shell.execute_reply": "2023-02-17T10:13:51.003410Z",
     "shell.execute_reply.started": "2023-02-17T10:13:50.465362Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Define the model. Set random_state to 1\n",
    "model = RandomForestRegressor(random_state=1)\n",
    "\n",
    "# fit your model\n",
    "model.fit(train_X,train_y)\n",
    "\n",
    "# Calculate the mean absolute error of your Random Forest model on the validation data\n",
    "val_mae = mean_absolute_error(val_y, model.predict(val_X))\n",
    "\n",
    "print(\"Validation MAE for Random Forest Model: {}\".format(val_mae))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to file you will use for predictions\n",
    "test_data_path = f'../input/{compitionName}/test.csv'\n",
    "\n",
    "# read test data file using pandas\n",
    "test_data = pd.read_csv(test_data_path)\n",
    "\n",
    "# create test_X which comes from test_data but includes only the columns you used for prediction.\n",
    "# The list of columns is stored in a variable called features\n",
    "test_X = test_data[features]\n",
    "\n",
    "# make predictions which we will submit. \n",
    "test_preds = model.predict(test_X)\n",
    "print(test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the code to save predictions in the format used for competition scoring\n",
    "\n",
    "output = pd.DataFrame({'Id': test_data.Id,\n",
    "                       'SalePrice': test_preds})\n",
    "output.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
